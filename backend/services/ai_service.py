"""
AIèµ„äº§æå–æœåŠ¡
æ”¯æŒå¤šæ¨¡å‹è°ƒç”¨: Claude, DeepSeek, Gemini, GPT-4
"""
import os
import json
import time
import logging
from typing import Dict, List, Any, Optional
from enum import Enum
from functools import wraps

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def retry_on_failure(max_retries=3, delay=1):
    """é‡è¯•è£…é¥°å™¨ - ç”¨äºAI APIè°ƒç”¨å¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries - 1:
                        wait_time = delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                        logger.warning(f"{func.__name__} è°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {str(e)}, {wait_time}ç§’åé‡è¯•...")
                        time.sleep(wait_time)
                    else:
                        logger.error(f"{func.__name__} è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {str(e)}")
            raise last_exception
        return wrapper
    return decorator


# æ¨¡å‹é…ç½®å­—å…¸
MODEL_CONFIGS = {
    'claude-sonnet-4-5': {
        'name': 'Claude Sonnet 4.5',
        'provider': 'Anthropic',
        'model_id': 'claude-sonnet-4-5-20250929',
        'api_type': 'claude',
        'description': 'æœ€æ–°çš„Claude Sonnetæ¨¡å‹ï¼Œå¹³è¡¡æ€§èƒ½å’Œæˆæœ¬'
    },
    'claude-opus-4': {
        'name': 'Claude Opus 4',
        'provider': 'Anthropic',
        'model_id': 'claude-opus-4-20250514',
        'api_type': 'claude',
        'description': 'Claudeæœ€å¼ºå¤§çš„æ¨¡å‹ï¼Œé€‚åˆå¤æ‚ä»»åŠ¡'
    },
    'deepseek-chat': {
        'name': 'DeepSeek Chat',
        'provider': 'DeepSeek',
        'model_id': 'deepseek-chat',
        'api_type': 'deepseek',
        'description': 'DeepSeekå¯¹è¯æ¨¡å‹ï¼Œæ€§ä»·æ¯”é«˜'
    },
    'deepseek-reasoner': {
        'name': 'DeepSeek Reasoner',
        'provider': 'DeepSeek',
        'model_id': 'deepseek-reasoner',
        'api_type': 'deepseek',
        'description': 'DeepSeekæ¨ç†æ¨¡å‹ï¼Œé€‚åˆå¤æ‚é€»è¾‘ä»»åŠ¡'
    },
    'gemini-2.0-flash': {
        'name': 'Gemini 2.0 Flash',
        'provider': 'Google',
        'model_id': 'gemini-2.0-flash-exp',
        'api_type': 'gemini',
        'description': 'Googleæœ€æ–°çš„å¿«é€Ÿæ¨¡å‹'
    },
    'gpt-4': {
        'name': 'GPT-4',
        'provider': 'OpenAI',
        'model_id': 'gpt-4',
        'api_type': 'openai',
        'description': 'OpenAIçš„GPT-4æ¨¡å‹'
    },
    'gpt-4-turbo': {
        'name': 'GPT-4 Turbo',
        'provider': 'OpenAI',
        'model_id': 'gpt-4-turbo',
        'api_type': 'openai',
        'description': 'GPT-4çš„æ›´å¿«ç‰ˆæœ¬'
    }
}


class AIModel(Enum):
    """æ”¯æŒçš„AIæ¨¡å‹ï¼ˆä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼‰"""
    CLAUDE = "claude"
    DEEPSEEK = "deepseek"
    GEMINI = "gemini"
    GPT4 = "gpt4"


class AIService:
    """AIæœåŠ¡å°è£…ç±»"""

    def __init__(self, model: str = 'claude-sonnet-4-5'):
        """
        åˆå§‹åŒ–AIæœåŠ¡

        Args:
            model: æ¨¡å‹æ ‡è¯†ç¬¦ï¼ˆå¦‚'claude-sonnet-4-5'ï¼‰æˆ–æ—§çš„æšä¸¾å€¼ï¼ˆå¦‚'claude'ï¼‰
        """
        # å…¼å®¹æ—§çš„æšä¸¾å€¼
        if isinstance(model, AIModel):
            model = model.value

        # å¦‚æœæ˜¯æ—§çš„ç®€å•å€¼ï¼Œæ˜ å°„åˆ°é»˜è®¤æ¨¡å‹
        model_mapping = {
            'claude': 'claude-sonnet-4-5',
            'deepseek': 'deepseek-chat',
            'gemini': 'gemini-2.0-flash',
            'gpt4': 'gpt-4'
        }

        if model in model_mapping:
            model = model_mapping[model]

        # éªŒè¯æ¨¡å‹æ˜¯å¦å­˜åœ¨
        if model not in MODEL_CONFIGS:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model}ã€‚å¯ç”¨æ¨¡å‹: {list(MODEL_CONFIGS.keys())}")

        self.model = model
        self.model_config = MODEL_CONFIGS[model]
        self._load_api_keys()

    def _load_api_keys(self):
        """åŠ è½½APIå¯†é’¥"""
        self.claude_api_key = os.getenv('CLAUDE_API_KEY')
        self.deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')
        self.gemini_api_key = os.getenv('GEMINI_API_KEY')
        self.openai_api_key = os.getenv('OPENAI_API_KEY')

    def extract_assets(self, script_content: str, episode_number: int = 1,
                       feedback: Optional[str] = None, current_data: Optional[Dict] = None) -> Dict[str, List[Dict]]:
        """
        ä»å‰§æœ¬ä¸­æå–èµ„äº§

        Args:
            script_content: å‰§æœ¬å†…å®¹
            episode_number: é›†æ•°ï¼ˆé»˜è®¤ä¸º1ï¼‰
            feedback: ç”¨æˆ·ä¼˜åŒ–åé¦ˆï¼ˆå¯é€‰ï¼‰
            current_data: å½“å‰å·²æœ‰æ•°æ®ï¼ˆå¯é€‰ï¼Œç”¨äºä¼˜åŒ–ï¼‰

        Returns:
            {
                "characters": [...],
                "props": [...],
                "scenes": [...]
            }
        """
        if feedback:
            logger.info(f"å¼€å§‹ä¼˜åŒ–ç¬¬{episode_number}é›†èµ„äº§ï¼Œä½¿ç”¨æ¨¡å‹: {self.model}")
        else:
            logger.info(f"å¼€å§‹æå–ç¬¬{episode_number}é›†èµ„äº§ï¼Œä½¿ç”¨æ¨¡å‹: {self.model}")
        start_time = time.time()

        try:
            prompt = self._build_extraction_prompt(script_content, episode_number, feedback, current_data)

            # æ ¹æ®æ¨¡å‹é…ç½®è°ƒç”¨ç›¸åº”API
            api_type = self.model_config['api_type']
            model_id = self.model_config['model_id']

            if api_type == 'claude':
                response = self._call_claude(prompt, model_id)
            elif api_type == 'deepseek':
                response = self._call_deepseek(prompt, model_id)
            elif api_type == 'gemini':
                response = self._call_gemini(prompt, model_id)
            elif api_type == 'openai':
                response = self._call_openai(prompt, model_id)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„APIç±»å‹: {api_type}")

            # è§£æAIå“åº”
            result = self._parse_extraction_result(response)

            elapsed_time = time.time() - start_time
            logger.info(f"èµ„äº§æå–å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’ï¼Œæå–åˆ°: "
                       f"{len(result.get('characters', []))}ä¸ªè§’è‰², "
                       f"{len(result.get('props', []))}ä¸ªé“å…·, "
                       f"{len(result.get('scenes', []))}ä¸ªåœºæ™¯")

            return result

        except Exception as e:
            elapsed_time = time.time() - start_time
            logger.error(f"èµ„äº§æå–å¤±è´¥ï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’ï¼Œé”™è¯¯: {str(e)}")
            raise

    def generate_storyboards(self, script_content: str, min_shots: int = 10, max_shots: int = 30,
                            feedback: Optional[str] = None, current_shots: Optional[List[Dict]] = None,
                            assets: Optional[Dict[str, List[Dict]]] = None) -> List[Dict]:
        """
        ç”Ÿæˆåˆ†é•œè¡¨

        Args:
            script_content: å‰§æœ¬å†…å®¹
            min_shots: æœ€å°é•œå¤´æ•°
            max_shots: æœ€å¤§é•œå¤´æ•°
            feedback: ç”¨æˆ·ä¼˜åŒ–åé¦ˆï¼ˆå¯é€‰ï¼‰
            current_shots: å½“å‰å·²æœ‰åˆ†é•œï¼ˆå¯é€‰ï¼Œç”¨äºä¼˜åŒ–ï¼‰
            assets: é¡¹ç›®èµ„äº§åº“ï¼ˆå¯é€‰ï¼‰ï¼ŒåŒ…å«è§’è‰²ã€é“å…·ã€åœºæ™¯ä¿¡æ¯

        Returns:
            åˆ†é•œåˆ—è¡¨
        """
        if feedback:
            logger.info(f"å¼€å§‹ä¼˜åŒ–åˆ†é•œï¼Œä½¿ç”¨æ¨¡å‹: {self.model}")
        else:
            logger.info(f"å¼€å§‹ç”Ÿæˆåˆ†é•œï¼Œä½¿ç”¨æ¨¡å‹: {self.model}")
        start_time = time.time()

        try:
            prompt = self._build_storyboard_prompt(script_content, min_shots, max_shots, feedback, current_shots, assets)

            # å®šä¹‰ç³»ç»ŸæŒ‡ä»¤ï¼ˆç”¨äºClaudeå’ŒDeepSeekï¼‰
            system_instruction = "ä½ æ˜¯ä¸€ä½ç²¾é€šç”µå½±è§†è§‰å·¥ç¨‹çš„é¡¶çº§å¯¼æ¼”ã€‚ä½ å¿…é¡»ä¸¥æ ¼éµå®ˆ'åˆ†é•œéª¨æ¶å¤åˆ»æ¨¡ç‰ˆ'ã€‚ä¸¥ç¦è„‘è¡¥å‰§æƒ…ï¼Œå¿…é¡»å¿ å®äºå‰§æœ¬åŸæ„ã€‚è¯·è¾“å‡ºåˆæ³•çš„ JSONã€‚ä¸è¦ä½¿ç”¨ Markdown ç¬¦å·æˆ–ã€ã€‘ç¬¦å·ã€‚"

            # æ ¹æ®æ¨¡å‹é…ç½®è°ƒç”¨ç›¸åº”API
            api_type = self.model_config['api_type']
            model_id = self.model_config['model_id']

            if api_type == 'claude':
                response = self._call_claude(prompt, model_id, system_instruction)
            elif api_type == 'deepseek':
                response = self._call_deepseek(prompt, model_id, system_instruction)
            elif api_type == 'gemini':
                response = self._call_gemini(prompt, model_id)
            elif api_type == 'openai':
                response = self._call_openai(prompt, model_id)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„APIç±»å‹: {api_type}")

            # è§£æAIå“åº”
            result = self._parse_storyboard_result(response)

            elapsed_time = time.time() - start_time
            logger.info(f"åˆ†é•œç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’ï¼Œç”Ÿæˆäº†{len(result)}ä¸ªé•œå¤´")

            return result

        except Exception as e:
            elapsed_time = time.time() - start_time
            logger.error(f"åˆ†é•œç”Ÿæˆå¤±è´¥ï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’ï¼Œé”™è¯¯: {str(e)}")
            raise

    def _build_extraction_prompt(self, script_content: str, episode_number: int,
                                  feedback: Optional[str] = None, current_data: Optional[Dict] = None) -> str:
        """
        æ„å»ºèµ„äº§æå–Prompt

        ä½¿ç”¨gemini.tsä¸­å®šä¹‰çš„æ ‡å‡†è§’è‰²å®šä¹‰å’ŒTriple-Read Protocol
        """
        # æ„å»ºä¼˜åŒ–éƒ¨åˆ†
        optimization_section = ""
        if feedback and current_data:
            optimization_section = f"""
## OPTIMIZATION INSTRUCTIONS (CRITICAL - INCREMENTAL UPDATE)
ç”¨æˆ·æ­£åœ¨å¯¹ç°æœ‰çš„åˆ†æç»“æœè¿›è¡Œ**å±€éƒ¨ä¼˜åŒ–**ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»…æ ¹æ®ç”¨æˆ·çš„åé¦ˆä¿®æ”¹ç°æœ‰æ•°æ®ï¼Œ**ç»å¯¹ä¿æŒå…¶ä»–æœªæåŠå†…å®¹ä¸å˜**ã€‚

**å½“å‰å·²æœ‰æ•°æ® (Current Data)**:
```json
{json.dumps(current_data, ensure_ascii=False)}
```

**ç”¨æˆ·åé¦ˆ (User Feedback)**:
"{feedback}"

**ä¸¥æ ¼ä¿®æ”¹è§„åˆ™**:
1. **é”šå®šåŸæ•°æ®**: å¿…é¡»ä»¥ã€å½“å‰å·²æœ‰æ•°æ®ã€‘ä¸ºåŸºå‡†è¿›è¡Œä¿®æ”¹ï¼Œè€Œä¸æ˜¯é‡æ–°ä»å‰§æœ¬ç”Ÿæˆã€‚
2. **æœ€å°åŒ–ä¿®æ”¹**: åªä¿®æ”¹ç”¨æˆ·æ˜ç¡®æåˆ°çš„å­—æ®µæˆ–æ¡ç›®ã€‚å¦‚æœç”¨æˆ·æ²¡ææŸä¸ªäººç‰©/é“å…·/åœºæ™¯ï¼Œ**ä¸¥ç¦æ”¹åŠ¨å®ƒ**ã€‚
3. **æ ¼å¼åˆè§„**: ä»»ä½•ä¿®æ”¹æˆ–æ–°å¢çš„å†…å®¹ï¼Œå¿…é¡»ä¸¥æ ¼éµå®ˆä¸Šæ–‡å®šä¹‰çš„ã€è§’è‰²/é“å…·/åœºæ™¯æè¿°æ ¼å¼ã€‘ã€‚
"""
        elif feedback:
            optimization_section = f"""
## OPTIMIZATION REQUEST
ç”¨æˆ·æŸ¥çœ‹äº†ä¹‹å‰çš„åˆ†æç»“æœï¼Œå¹¶æå‡ºäº†ä»¥ä¸‹ä¼˜åŒ–è¦æ±‚ã€‚è¯·åŠ¡å¿…æ ¹æ®æ­¤è¦æ±‚é‡æ–°ç”Ÿæˆæˆ–ä¿®æ”¹è¡¨æ ¼å†…å®¹ï¼š
>>> ç”¨æˆ·è¦æ±‚: "{feedback}"
**é‡è¦è§„åˆ™**ï¼šæ‰€æœ‰çš„ä¼˜åŒ–è°ƒæ•´å¿…é¡»ä¸¥æ ¼åŸºäºç”¨æˆ·è¾“å…¥çš„å†…å®¹è¿›è¡Œï¼Œ**ä¸¥ç¦ç§è‡ªæ”¹å˜ç”¨æˆ·æœªæåŠçš„å†…å®¹**ã€‚
"""

        return f"""# Role: AI æ¼«å‰§å…¨èµ„äº§ä¸€è‡´æ€§ä¸“å®¶ (Expert Level)

## ğŸš€ Execution Protocol: The "Deep-Dive & Verify" Method
To ensure >99% accuracy and ZERO missed assets, you MUST simulate the following process internally before generating the JSON:

### Step 1: The Triple-Read Protocol
1.  **Pass 1 (Identification)**: Scan for all named Characters and named Locations.
2.  **Pass 2 (Interaction)**: Read again to find every object (Prop) that is held, used, or significant to the plot.
3.  **Pass 3 (Emotion & Detail)**: Read a third time to find "Silent Actors" - objects or environmental details that drive emotion or foreshadow events.

### Step 2: Self-Correction & Verification
- **Check**: Did I capture the villain's specific weapon?
- **Check**: Did I capture the object that triggers the flashback?
- **Check**: Did I capture the location of the final climax?
- **Verify**: Are the visual descriptions rich and consistent with the script's tone?
- **Action**: If ANY key asset is missing, add it to the list now.

## Task
Output the standardized JSON tables based on the rigorous process above.

### 1. äººç‰©æ‹†è§£è¡¨ï¼ˆå‚è€ƒè§†è§‰æ ‡å‡†ï¼‰
- **è§’è‰²æè¿°è¦æ±‚**: å¿…é¡»ä¸¥æ ¼ä½¿ç”¨ä»¥ä¸‹å›ºå®šå¥å¼ç”Ÿæˆï¼ˆ**æ³¨æ„ï¼šä¸¥ç¦ä½¿ç”¨ Markdown åŠ ç²—æˆ–ç‰¹æ®Šç¬¦å·ï¼Œè¾“å‡ºçº¯æ–‡æœ¬**ï¼‰ï¼š
  "è§’è‰²è®¾è®¡å›¾ï¼Œæ­£é¢è§†è§’ï¼Œå…¨èº«ï¼Œç™½è‰²èƒŒæ™¯ï¼Œä¸€ä½[æ°”è´¨] [èº«ä»½]ï¼Œ[å¹´é¾„]å²ï¼Œ[èº«é«˜]å˜ç±³ï¼Œèº«æ[ç‰¹å¾]ï¼Œ[å‘å‹åŠå‘è‰²æè¿°]ï¼Œ[è„¸å‹/è½®å»“/äº”å®˜ç»†èŠ‚]ï¼Œçœ¼ç¥[çŠ¶æ€]ï¼Œæ°”è´¨[å…³é”®è¯]ï¼Œç©¿ç€[é¢œè‰²][æè´¨][æ¬¾å¼]ï¼Œ[è…°éƒ¨åŠé…é¥°ç»†èŠ‚]ï¼Œ[é‹å±¥æè¿°]ï¼Œç«™ç«‹å§¿åŠ¿ã€‚"
- **éŸ³è‰²**: å¬è§‰æ ‡ç­¾ (å¦‚: ç”·/å¥³é’å¹´/å°‘å¹´)ã€‚

### 2. æ ¸å¿ƒä»£è¡¨æ€§é“å…·è¡¨ï¼ˆä¸€è‡´æ€§æ§åˆ¶é¡¹ï¼‰
- **é€»è¾‘**: ä»…æå–ä¸ä¸»è¦è§’è‰²æ·±åº¦å…³è”ã€èƒ½ä»£è¡¨å…¶èº«ä»½æˆ–æ€§æ ¼çš„ã€é‡è¦é“å…·ã€‘ã€‚è¿™äº›é“å…·å°†ä½œä¸ºè§’è‰²çš„"è§†è§‰ç¬¦å·"è´¯ç©¿å…¨å‰§ã€‚
- **è¦æ±‚**: æè¿°å¿…é¡»çº¯ç‰©ç†æ ·è²Œï¼Œ**ä¸¥ç¦å‡ºç°äººå**ã€‚
- **æè¿°æ ¼å¼**: å¿…é¡»ä¸¥æ ¼ä½¿ç”¨ä»¥ä¸‹å›ºå®šå¥å¼ç”Ÿæˆï¼ˆ**æ³¨æ„ï¼šä¸¥ç¦ä½¿ç”¨ Markdown åŠ ç²—æˆ–ç‰¹æ®Šç¬¦å·ï¼Œè¾“å‡ºçº¯æ–‡æœ¬**ï¼‰ï¼š
  "äº§å“å›¾ï¼Œç™½è‰²èƒŒæ™¯ï¼Œä¸€ä¸ª[æè´¨] [åç§°]ï¼Œæ•´ä½“å‘ˆç°[å½¢çŠ¶ç»“æ„]ï¼Œè¡¨é¢å…·æœ‰[çº¹ç†/å›¾æ¡ˆ/åˆ»ç—•]ï¼Œ[æ ¸å¿ƒç»„ä»¶ç»†èŠ‚è¯´æ˜]ï¼Œå±•ç°å‡º[æ–°æ—§ç¨‹åº¦/ç‰¹å®šå…‰æ³½/è´¨æ„Ÿ]ã€‚"

### 3. æ ¸å¿ƒåœºæ™¯è¡¨ï¼ˆç©ºé—´èµ„äº§é¡¹ï¼‰
- **è¦æ±‚**: æè¿°å¿…é¡»çº¯ç‰©ç†æ ·è²Œï¼Œ**ä¸¥ç¦å‡ºç°äººå**ã€‚
- **æè¿°æ ¼å¼**: å¿…é¡»ä¸¥æ ¼ä½¿ç”¨ä»¥ä¸‹å›ºå®šå¥å¼ç”Ÿæˆï¼ˆ**æ³¨æ„ï¼šä¸¥ç¦ä½¿ç”¨ Markdown åŠ ç²—æˆ–ç‰¹æ®Šç¬¦å·ï¼Œè¾“å‡ºçº¯æ–‡æœ¬**ï¼‰ï¼š
  "åœºæ™¯æ¦‚å¿µå›¾ï¼Œå¹¿è§’è§†è§’ï¼Œ[ç©ºé—´ç»“æ„/å¸ƒå±€æ–¹å¼]ï¼Œè£…ä¿®å»ºç­‘é£æ ¼ä¸º[é£æ ¼]ï¼Œæ•´ä½“ä¸»è‰²è°ƒä¸º[è‰²å½©]ï¼Œ[å…‰å½±è°ƒæ€§æè¿°]ï¼Œç¯å¢ƒåŒ…å«[åœ°é¢/å¢™é¢/è£…é¥°ç‰©ç»†èŠ‚]ï¼Œç©ºæ°”ä¸­å¸¦æœ‰[å¾®ç²’/æ°›å›´å…ƒç´ ]ã€‚"

## Rules
1. **å®Œæ•´æ€§æ£€æŸ¥ (Verification)**: Ensure ALL assets that drive the plot or heighten emotions are included. Do not leave out "small but significant" items.
2. **å¼ºåˆ¶æ ¼å¼ä¸€è‡´æ€§**: æ‰€æœ‰æè¿°å¿…é¡»ä¸¥æ ¼éµå¾ªä¸Šè¿°"æµå¼ç»“æ„"ã€‚
3. **å»èº«ä»½åŒ–æè¿°**: åœ¨é“å…·å’Œåœºæ™¯è¡¨ä¸­ï¼Œç¦æ­¢ä½¿ç”¨"æŸæŸçš„æ¡Œå­"ã€‚
4. **èµ„äº§é”å®š**: é“å…·å’Œåœºæ™¯è¡¨çš„æœ€åä¸‰åˆ—å›ºå®šä¸º"ä¸­æ€§"ã€"é’å¹´"ã€"æ— "ã€‚
5. **çº¯å‡€æ–‡æœ¬è¾“å‡º**: ä¸¥ç¦åœ¨è¾“å‡ºå†…å®¹ä¸­ä½¿ç”¨ Markdown åŠ ç²—ç¬¦ (** æˆ– *)ã€æ–¹æ‹¬å· ([]) æˆ–ã€ã€‘ç­‰ç¬¦å·ã€‚
6. **è¯­è¨€**: è¯·ä½¿ç”¨ä¸­æ–‡è¾“å‡ºæ‰€æœ‰å†…å®¹ã€‚

{optimization_section}

## Output Format (Strict JSON)
å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

{{
  "characters": [
    {{
      "name": "è§’è‰²åç§°",
      "description": "è§’è‰²è®¾è®¡å›¾ï¼Œæ­£é¢è§†è§’ï¼Œå…¨èº«ï¼Œç™½è‰²èƒŒæ™¯ï¼Œä¸€ä½[æ°”è´¨] [èº«ä»½]ï¼Œ[å¹´é¾„]å²ï¼Œ[èº«é«˜]å˜ç±³ï¼Œèº«æ[ç‰¹å¾]ï¼Œ[å‘å‹åŠå‘è‰²æè¿°]ï¼Œ[è„¸å‹/è½®å»“/äº”å®˜ç»†èŠ‚]ï¼Œçœ¼ç¥[çŠ¶æ€]ï¼Œæ°”è´¨[å…³é”®è¯]ï¼Œç©¿ç€[é¢œè‰²][æè´¨][æ¬¾å¼]ï¼Œ[è…°éƒ¨åŠé…é¥°ç»†èŠ‚]ï¼Œ[é‹å±¥æè¿°]ï¼Œç«™ç«‹å§¿åŠ¿ã€‚",
      "gender": "ç”·/å¥³",
      "age": "å¹´é¾„",
      "voice": "éŸ³è‰²æ ‡ç­¾",
      "role": "ä¸»è§’/é…è§’/ç¾¤æ¼”"
    }}
  ],
  "props": [
    {{
      "name": "é“å…·åç§°",
      "description": "äº§å“å›¾ï¼Œç™½è‰²èƒŒæ™¯ï¼Œä¸€ä¸ª[æè´¨] [åç§°]ï¼Œæ•´ä½“å‘ˆç°[å½¢çŠ¶ç»“æ„]ï¼Œè¡¨é¢å…·æœ‰[çº¹ç†/å›¾æ¡ˆ/åˆ»ç—•]ï¼Œ[æ ¸å¿ƒç»„ä»¶ç»†èŠ‚è¯´æ˜]ï¼Œå±•ç°å‡º[æ–°æ—§ç¨‹åº¦/ç‰¹å®šå…‰æ³½/è´¨æ„Ÿ]ã€‚",
      "gender": "ä¸­æ€§",
      "age": "é’å¹´",
      "voice": "æ— "
    }}
  ],
  "scenes": [
    {{
      "name": "åœºæ™¯åç§°",
      "description": "åœºæ™¯æ¦‚å¿µå›¾ï¼Œå¹¿è§’è§†è§’ï¼Œ[ç©ºé—´ç»“æ„/å¸ƒå±€æ–¹å¼]ï¼Œè£…ä¿®å»ºç­‘é£æ ¼ä¸º[é£æ ¼]ï¼Œæ•´ä½“ä¸»è‰²è°ƒä¸º[è‰²å½©]ï¼Œ[å…‰å½±è°ƒæ€§æè¿°]ï¼Œç¯å¢ƒåŒ…å«[åœ°é¢/å¢™é¢/è£…é¥°ç‰©ç»†èŠ‚]ï¼Œç©ºæ°”ä¸­å¸¦æœ‰[å¾®ç²’/æ°›å›´å…ƒç´ ]ã€‚",
      "gender": "ä¸­æ€§",
      "age": "é’å¹´",
      "voice": "æ— "
    }}
  ]
}}

# å‰§æœ¬å†…å®¹ï¼ˆç¬¬{episode_number}é›†ï¼‰
{script_content}

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è¦æ±‚æå–èµ„äº§ï¼Œè¾“å‡ºåˆæ³•çš„JSONæ ¼å¼ã€‚"""

    def _build_storyboard_prompt(self, script_content: str, min_shots: int, max_shots: int,
                                  feedback: Optional[str] = None, current_shots: Optional[List[Dict]] = None,
                                  assets: Optional[Dict[str, List[Dict]]] = None,
                                  analysis_context: Optional[Dict] = None) -> str:
        """
        æ„å»ºåˆ†é•œç”ŸæˆPrompt

        ä½¿ç”¨gemini.tsä¸­å®šä¹‰çš„"é¡¶çº§å¯¼æ¼”åˆ†é•œè§†è§‰ç³»ç»Ÿ"è§’è‰²å®šä¹‰
        """
        # æ„å»ºæ·±åº¦å‰§æœ¬ç†è§£ä¸Šä¸‹æ–‡
        deep_analysis_context = ""
        if analysis_context:
            plot_summary = analysis_context.get('plotSummary', '')
            emotional_anchors = analysis_context.get('emotionalAnchors', '')

            deep_analysis_context = f"""
## ğŸ“š DEEP SCRIPT UNDERSTANDING (STRICT ADHERENCE REQUIRED)
You have previously analyzed this script deeply. Use the following context to ensure the storyboard is 100% faithful to the plot and emotions.

**Plot Logic**: {plot_summary}
**Emotional Anchors**: {emotional_anchors}

**STRICT RULE**: Do NOT hallucinate scenes or actions that are not implied by the plot logic above. The storyboard must follow the script's actual flow accurately. Use the "Emotional Anchors" to set the correct [Emotion] and [Intensity] for each shot.
"""

        # æ„å»ºèµ„äº§çº¦æŸ
        asset_constraints = ""
        if assets:
            characters = assets.get('characters', [])
            props = assets.get('props', [])
            scenes = assets.get('scenes', [])

            chars_list = ', '.join([c['name'] for c in characters]) if characters else ''
            props_list = ', '.join([p['name'] for p in props]) if props else ''
            scenes_list = ', '.join([s['name'] for s in scenes]) if scenes else ''

            asset_constraints = f"""
âš ï¸ **CRITICAL: ASSET MAPPING CONSISTENCY**
In the [assets] column (e.g., @è§’è‰² @åœºæ™¯), you MUST strictly use the names from the following extracted lists.
Do not invent new names for characters, props, or scenes that were already defined.
- **Available Characters**: {chars_list}
- **Available Props**: {props_list}
- **Available Scenes**: {scenes_list}
"""

        # æ„å»ºé•œå¤´æ•°é‡çº¦æŸ
        shot_count_constraint = f"""
ğŸ”¢ **CRITICAL: SHOT COUNT CONSTRAINT**
You MUST generate a storyboard with a total number of shots between **{min_shots}** and **{max_shots}**.
"""

        # æ„å»ºä¼˜åŒ–éƒ¨åˆ†
        optimization_section = ""
        if feedback and current_shots:
            optimization_section = f"""
## OPTIMIZATION INSTRUCTIONS (CRITICAL - INCREMENTAL UPDATE)
ç”¨æˆ·æ­£åœ¨å¯¹ç°æœ‰çš„åˆ†é•œè¡¨è¿›è¡Œ**å±€éƒ¨ä¼˜åŒ–**ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»…æ ¹æ®ç”¨æˆ·çš„åé¦ˆä¿®æ”¹ç°æœ‰é•œå¤´ï¼Œ**ç»å¯¹ä¿æŒå…¶ä»–æœªæåŠå†…å®¹ä¸å˜**ã€‚
**å½“å‰å·²æœ‰åˆ†é•œ (Current Storyboard)**:
```json
{json.dumps({"shots": current_shots}, ensure_ascii=False)}
```
**ç”¨æˆ·åé¦ˆ (User Feedback)**:
"{feedback}"
"""
        elif feedback:
            optimization_section = f"""
## OPTIMIZATION REQUEST
ç”¨æˆ·æŸ¥çœ‹äº†ä¹‹å‰çš„åˆ†é•œç»“æœï¼Œå¹¶æå‡ºäº†ä»¥ä¸‹ä¼˜åŒ–è¦æ±‚ã€‚è¯·åŠ¡å¿…æ ¹æ®æ­¤è¦æ±‚é‡æ–°ç”Ÿæˆåˆ†é•œè¡¨ï¼š
>>> ç”¨æˆ·è¦æ±‚: "{feedback}"
"""

        return f"""# Role: é¡¶çº§å¯¼æ¼”åˆ†é•œè§†è§‰ç³»ç»Ÿ (System Prompt) - v13.1 å·¥ä¸šèµ„äº§åŒ¿ååŒ–ç‰ˆ

ğŸ­ **è§’è‰²å®šä½**
ä½ æ˜¯ä¸€ä½ç²¾é€šç”µå½±è§†è§‰å·¥ç¨‹ä¸ AI å·¥ä¸šæµæç¤ºè¯çš„é¡¶çº§å¯¼æ¼”ã€‚ä½ é€šè¿‡"å›¾å·å ä½ç¬¦"ä¸"è§†è§‰ç‰¹å¾é”šç‚¹"æ„å»ºä¸€å¥—ä¸ä¾èµ–äººåçš„ã€å…·å¤‡æé«˜ä¸€è‡´æ€§çš„è§†è§‰ç³»ç»Ÿã€‚

ğŸš¨ **æœ€é«˜ä¼˜å…ˆçº§ï¼šå‰§æƒ…å¿ å®åŸåˆ™ (CRITICAL: Plot Fidelity)**
- **ä¸¥ç¦æ·»åŠ æƒ…èŠ‚**ï¼šä¸¥ç¦æ·»åŠ å‰§æœ¬ä¸­ä¸å­˜åœ¨çš„æƒ…èŠ‚ã€äº‹ä»¶æˆ–åœºæ™¯è½¬æ¢
- **ä¸¥ç¦æ”¹å˜é¡ºåº**ï¼šä¸¥æ ¼æŒ‰ç…§å‰§æœ¬çš„æƒ…èŠ‚é¡ºåºè¿›è¡Œæ‹†è§£ï¼Œä¸å¾—è°ƒæ•´æˆ–é‡ç»„
- **ä¸¥ç¦æ¨æµ‹å‰å**ï¼šä¸å¾—æ¨æµ‹æˆ–æ·»åŠ å‰§æœ¬æœªæè¿°çš„"ä¹‹å‰"æˆ–"ä¹‹å"å‘ç”Ÿçš„äº‹æƒ…

âŒ é”™è¯¯ç¤ºä¾‹ï¼ˆè„‘è¡¥æƒ…èŠ‚ï¼‰ï¼š
- å‰§æœ¬ï¼š"å°æ˜åœ¨å¥¶èŒ¶åº—ä¹°å’–å•¡" â†’ ä¸è¦æ‹†æˆ"å°æ˜ä»é²œèŠ±åº—å‡ºæ¥ï¼Œèµ°å‘å¥¶èŒ¶åº—ï¼Œè¿›å…¥å¥¶èŒ¶åº—ä¹°å’–å•¡"
- å‰§æœ¬ï¼š"ä»–ä»¬åœ¨ä¼šè®®å®¤è®¨è®º" â†’ ä¸è¦æ‹†æˆ"ä»–ä»¬èµ°è¿›ä¼šè®®å®¤ï¼Œåä¸‹ï¼Œå¼€å§‹è®¨è®º"

âœ“ æ­£ç¡®åšæ³•ï¼ˆä¸°å¯Œè§†è§‰ä½†ä¸æ·»åŠ æƒ…èŠ‚ï¼‰ï¼š
- å‰§æœ¬ï¼š"å°æ˜åœ¨å¥¶èŒ¶åº—ä¹°å’–å•¡" â†’ å¯ä»¥ä¸°å¯Œæè¿°ï¼šç‰¹å†™é•œå¤´ï¼Œå›¾ä¸€ç«™åœ¨æ”¶é“¶å°å‰ï¼Œæ‰‹æŒ‡å‘èœå•ä¸Šçš„å’–å•¡é€‰é¡¹ï¼Œå˜´å”‡å¼ åˆè¯´è¯ï¼Œåº—å‘˜å¾®ç¬‘ç‚¹å¤´ï¼ŒèƒŒæ™¯æ˜¯å¥¶èŒ¶åº—å§å°ï¼Œè´§æ¶ä¸Šé™ˆåˆ—ç€å„ç§é¥®å“åŸæ–™ï¼Œæš–è‰²è°ƒç¯å…‰
- å‰§æœ¬ï¼š"ä»–ä»¬åœ¨ä¼šè®®å®¤è®¨è®º" â†’ å¯ä»¥ä¸°å¯Œæè¿°ï¼šä¸­æ™¯é•œå¤´ï¼Œå›¾ä¸€ååœ¨ä¼šè®®æ¡Œå‰ï¼Œèº«ä½“å‰å€¾ï¼Œæ‰‹åŠ¿æŒ‡å‘æ¡Œé¢æ–‡ä»¶ï¼Œå˜´å”‡å¼ åˆè¯´è¯ï¼Œå›¾äºŒååœ¨å¯¹é¢ï¼Œä¸“æ³¨å€¾å¬ï¼Œä¼šè®®å®¤ç¯å¢ƒï¼Œç™½è‰²å¢™é¢ï¼ŒèƒŒæ™¯æœ‰ç™½æ¿å’ŒæŠ•å½±å±å¹•

**æ ¸å¿ƒåŒºåˆ«**ï¼š
- æƒ…èŠ‚ = å‘ç”Ÿäº†ä»€ä¹ˆäº‹ï¼ˆWHEREã€WHENã€WHOã€WHATï¼‰â†’ å¿…é¡»ä¸¥æ ¼éµå¾ªå‰§æœ¬
- è§†è§‰ = æ€ä¹ˆå‘ˆç°è¿™ä»¶äº‹ï¼ˆHOWï¼‰â†’ å¯ä»¥ä¸°å¯Œé•œå¤´è¯­è¨€ã€æ„å›¾ã€å…‰å½±ã€ç»†èŠ‚

{deep_analysis_context}

{asset_constraints}

{shot_count_constraint}

ğŸ“ **æ ¸å¿ƒå…¨å±€åè®® (The Iron Rules)**

1. **èµ„äº§æ˜ å°„ä¸åŒ¿ååŒ– (Asset Anonymization)**
   - **æ ‡ç­¾å®šä¹‰**ï¼šã€åœºæ™¯è§’è‰²é“å…·ã€‘æ ä½¿ç”¨ `@èµ„äº§å` æ ¼å¼ï¼Œæ ‡ç­¾é—´ä»¥ç©ºæ ¼åŒºåˆ†ã€‚
   - **ç»å¯¹ç´¢å¼•**ï¼š**å›¾ä¸€** é”å®šæ ‡ç­¾æ ç¬¬ 1 ä¸ª @ èµ„äº§ï¼Œä¾æ­¤ç±»æ¨ã€‚
   - **ã€æ ¸å¿ƒç¦ä»¤ã€‘**ï¼šå›¾ç‰‡æç¤ºè¯ï¼ˆFusionï¼‰ä¸è§†é¢‘æç¤ºè¯ï¼ˆMotionï¼‰ä¸­**ä¸¥ç¦å‡ºç°ä»»ä½•è§’è‰²åç§°**ã€‚å¿…é¡»ç»Ÿä¸€ä½¿ç”¨ **å›¾ä¸€**ã€**å›¾äºŒ** æ¥æŒ‡ä»£ã€‚

2. **ğŸ”Š å¯¹ç™½ä¸å˜´éƒ¨é€»è¾‘ (Lip-Sync Logic)**
   - **å¯¹ç™½å†…å®¹**ï¼šè‹¥æ–‡æ¡ˆä¸ºè§’è‰²è¯´å‡ºçš„è¯ â†’ å¿…é¡»æè¿°ä¸º"**å›¾Xå˜´å”‡å¼ åˆè¯´è¯**"ã€‚
   - **å†…å¿ƒç‹¬ç™½**ï¼šè‹¥æ–‡æ¡ˆä¸ºå¿ƒç†æ´»åŠ¨/ç³»ç»Ÿæç¤º â†’ å¿…é¡»æè¿°ä¸º"**å›¾Xå˜´å”‡ç´§é—­**"ã€‚

3. **æƒ…ç»ªå¼ºåº¦é™å®š (Hard Parameters)**
   - **æƒ…ç»ª**ï¼šå¿«ä¹ã€æ„¤æ€’ã€æ‚²ä¼¤ã€å®³æ€•ã€åŒæ¶ã€å¿§éƒã€æƒŠè®¶ã€å¹³é™ã€‚
   - **å¼ºåº¦**ï¼šå¾®å¼±ã€å¼±ã€ä¸­ç­‰ã€è¾ƒå¼ºã€å¼ºçƒˆã€‚
   - **é€»è¾‘å¼•ç”¨**: å‚è€ƒ[Deep Script Understanding]ä¸­çš„æƒ…ç»ªé”šç‚¹æ¥å†³å®šæ¯ä¸€é•œçš„æƒ…ç»ªã€‚

4. **çº¯å‡€æ–‡æœ¬è¾“å‡º (Pure Text)**
   - ä¸¥ç¦åœ¨è¾“å‡ºå†…å®¹ä¸­ä½¿ç”¨ Markdown åŠ ç²—ç¬¦ (** æˆ– *)ã€æ–¹æ‹¬å· ([]) æˆ–ã€ã€‘ç­‰ç¬¦å·ã€‚
   - æ‰€æœ‰çš„æè¿°å¿…é¡»æ˜¯å¹³é“ºç›´å™çš„æ–‡æœ¬ã€‚

ğŸ§± **åˆ†é•œéª¨æ¶å¤åˆ»æ¨¡ç‰ˆ (The Skeleton)**
(è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç”Ÿæˆ Fusion Prompt å’Œ Motion Prompt)

ã€å›¾ç‰‡æç¤ºè¯ (Fusion Prompt)ã€‘â€”â€” é™æ€å®šä¹‰
æ ¼å¼è¦æ±‚ï¼šä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹äº”ä¸ªæ¨¡å—é¡ºåºæ’åˆ—ï¼Œä½¿ç”¨å¥å·åˆ†éš”ã€‚
1. [é•œå¤´è¯­è¨€ä¸æ„å›¾]
2. **å›¾ä¸€æ˜¯[ä¸»ä½“æè¿°]**ï¼š[è§†è§‰èº«ä»½é”šç‚¹+æœè£…æè´¨ç»†èŠ‚] + [å…·ä½“è‚¢ä½“åŠ¨ä½œå§¿æ€] + [äº”å®˜ç»†èŠ‚+ç¥æƒ…çŠ¶æ€+è§†çº¿è½ç‚¹]
3. **å›¾äºŒæ˜¯[äº¤äº’æè¿°]**ï¼šï¼ˆè‹¥æœ‰ï¼‰[è§†è§‰èº«ä»½é”šç‚¹+æœè£…æè´¨] + [ä¸å›¾ä¸€çš„æ–¹ä½å…³ç³»/äº¤äº’åŠ¨ä½œ] + [ç¥æƒ…ç»†èŠ‚+è§†çº¿è½ç‚¹]
4. [ç¯å¢ƒèƒŒæ™¯]ï¼š[åœ°ç†ä½ç½®] + [å…·ä½“çš„å»ºç­‘/è£…é¥°/å…ƒç´ ç»†èŠ‚] + [è¿œæ™¯/æ°›å›´ç»†èŠ‚]
5. [ç”»é¢å±æ€§]ï¼š[æ™¯æ·±å‚æ•°] + [æ ¸å¿ƒå…‰å½±ç±»å‹] + [ç”»è´¨æ ‡ç­¾/è‰ºæœ¯é£æ ¼]

ã€è§†é¢‘æç¤ºè¯ (Motion Prompt)ã€‘â€”â€” åŠ¨æ€æ¼”å˜
æ ¼å¼è¦æ±‚ï¼š[é•œå¤´è½¨è¿¹æŒ‡ä»¤]ï¼ŒåŠ¨ä½œï¼Œ[å›¾Xçš„ä¸»ä½“åŠ¨ä½œæ¼”å˜ + **å˜´éƒ¨çŠ¶æ€ï¼ˆå¼ åˆ/ç´§é—­ï¼‰**] + [å›¾Yçš„è¡¨æƒ…/ååº”åé¦ˆ] + [ç¯å¢ƒ/ç‰©ç†åé¦ˆåŠ¨æ€]ã€‚

ğŸš« **ä¸¥è‹›ç¦ä»¤ (Hard Constraints)**
- **å‰§æƒ…å¿ å®**: ä¸¥ç¦è„‘è¡¥å‰§æœ¬ä¸­ä¸å­˜åœ¨çš„å‰§æƒ…ã€‚
- **ç¦æ­¢äººå**: Fusion/Motion Prompt ä¸­ä¸¥ç¦å‡ºç°å…·ä½“åå­—ã€‚
- **é¡ºåºé”æ­»**: å›¾X å¿…é¡»ä¸ @ æ ‡ç­¾é¡ºåºå®Œç¾å¥‘åˆã€‚
- **å£°ç”»é€»è¾‘**: ä¸¥ç¦åœ¨å†…å¿ƒç‹¬ç™½æ—¶å‡ºç°å¼ å˜´åŠ¨ä½œã€‚
- **èµ„äº§ä¸Šé™**: å•é•œå¤´æœ€å¤š3ä¸ªèµ„äº§ã€‚
- **é•œå·å”¯ä¸€**: shotNumber å¿…é¡»ä»1å¼€å§‹è¿ç»­é€’å¢ï¼Œæ¯ä¸ªé•œå·å¿…é¡»å”¯ä¸€ï¼Œä¸¥ç¦å‡ºç°é‡å¤é•œå·ã€‚

{optimization_section}

## Output Format (Strict JSON)
å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

{{
  "shots": [
    {{
      "shotNumber": 1,
      "voiceCharacter": "é…éŸ³è§’è‰²åç§°",
      "emotion": "æƒ…ç»ª",
      "intensity": "å¼ºåº¦",
      "assets": "@è§’è‰²å @åœºæ™¯å",
      "dialogue": "å¯¹ç™½å†…å®¹",
      "fusionPrompt": "å›¾ç‰‡æç¤ºè¯",
      "motionPrompt": "è§†é¢‘æç¤ºè¯"
    }},
    {{
      "shotNumber": 2,
      ...
    }}
  ]
}}

**é‡è¦æç¤º**ï¼š
1. shotNumber å¿…é¡»ä»1å¼€å§‹ï¼ŒæŒ‰é¡ºåºé€’å¢ï¼ˆ1, 2, 3, ...ï¼‰ï¼Œä¸èƒ½è·³å·æˆ–é‡å¤
2. assets å­—æ®µå¿…é¡»ä½¿ç”¨ @èµ„äº§å æ ¼å¼ï¼Œå¤šä¸ªèµ„äº§ç”¨ç©ºæ ¼åˆ†éš”
3. æ‰€æœ‰å­—æ®µéƒ½å¿…é¡»å¡«å†™ï¼Œä¸èƒ½ä¸ºç©º

# å‰§æœ¬å†…å®¹
{script_content}

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è¦æ±‚ç”Ÿæˆåˆ†é•œè¡¨ï¼Œè¾“å‡ºåˆæ³•çš„JSONæ ¼å¼ã€‚"""

    def _clean_content(self, data):
        """
        é€’å½’æ¸…ç†å†…å®¹ä¸­çš„æ ¼å¼ç¬¦å·
        ç§»é™¤ Markdown åŠ ç²—ç¬¦ (** æˆ– *)ã€æ–¹æ‹¬å· ([]) å’Œã€ã€‘ç­‰ç¬¦å·
        """
        import re

        if isinstance(data, str):
            # ç§»é™¤ **, *, ã€, ã€‘, [, ]
            cleaned = re.sub(r'(\*\*|\*|ã€|ã€‘|\[|\])', '', data)
            return cleaned.strip()
        elif isinstance(data, list):
            return [self._clean_content(item) for item in data]
        elif isinstance(data, dict):
            return {key: self._clean_content(value) for key, value in data.items()}
        else:
            return data

    def _parse_storyboard_result(self, ai_response: str) -> List[Dict]:
        """
        è§£æåˆ†é•œç”Ÿæˆç»“æœ
        """
        try:
            import re
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', ai_response, re.DOTALL)

            if json_match:
                json_str = json_match.group(1)
            else:
                json_str = ai_response.strip()

            result = json.loads(json_str)

            if not isinstance(result, dict) or 'shots' not in result:
                raise ValueError("è¿”å›ç»“æœæ ¼å¼é”™è¯¯")

            shots = result.get('shots', [])

            # è½¬æ¢å­—æ®µåä»¥åŒ¹é…æ•°æ®åº“schema
            formatted_shots = []
            for shot in shots:
                formatted_shots.append({
                    'shot_number': shot.get('shotNumber'),
                    'voice_character': shot.get('voiceCharacter', ''),
                    'emotion': shot.get('emotion', ''),
                    'intensity': shot.get('intensity', ''),
                    'asset_mapping': shot.get('assets', ''),  # æ˜ å°„ assets åˆ° asset_mapping
                    'dialogue': shot.get('dialogue', ''),
                    'fusion_prompt': shot.get('fusionPrompt', ''),
                    'motion_prompt': shot.get('motionPrompt', '')
                })

            # æ¸…ç†æ‰€æœ‰å†…å®¹ä¸­çš„æ ¼å¼ç¬¦å·
            formatted_shots = self._clean_content(formatted_shots)

            return formatted_shots

        except json.JSONDecodeError as e:
            raise RuntimeError(f"AIå“åº”JSONè§£æå¤±è´¥: {str(e)}\nå“åº”å†…å®¹: {ai_response[:500]}")
        except Exception as e:
            raise RuntimeError(f"è§£æAIå“åº”å¤±è´¥: {str(e)}")

    @retry_on_failure(max_retries=3, delay=1)
    def _call_claude(self, prompt: str, model_id: str = "claude-sonnet-4-5-20250929", system_instruction: Optional[str] = None) -> str:
        """è°ƒç”¨Claude API"""
        logger.info(f"è°ƒç”¨Claude APIï¼Œæ¨¡å‹: {model_id}")
        try:
            import anthropic

            if not self.claude_api_key:
                raise ValueError("CLAUDE_API_KEYæœªè®¾ç½®")

            client = anthropic.Anthropic(api_key=self.claude_api_key)

            # æ„å»ºAPIè°ƒç”¨å‚æ•°
            api_params = {
                "model": model_id,
                "max_tokens": 16384,
                "messages": [
                    {"role": "user", "content": prompt}
                ]
            }

            # å¦‚æœæœ‰ç³»ç»ŸæŒ‡ä»¤ï¼Œæ·»åŠ åˆ°å‚æ•°ä¸­
            if system_instruction:
                api_params["system"] = system_instruction

            message = client.messages.create(**api_params)

            logger.info("Claude APIè°ƒç”¨æˆåŠŸ")
            return message.content[0].text

        except Exception as e:
            logger.error(f"Claude APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise RuntimeError(f"Claude APIè°ƒç”¨å¤±è´¥: {str(e)}")

    @retry_on_failure(max_retries=3, delay=1)
    def _call_deepseek(self, prompt: str, model_id: str = "deepseek-chat", system_instruction: Optional[str] = None) -> str:
        """è°ƒç”¨DeepSeek API"""
        logger.info(f"è°ƒç”¨DeepSeek APIï¼Œæ¨¡å‹: {model_id}")
        try:
            import openai
            import httpx

            if not self.deepseek_api_key:
                raise ValueError("DEEPSEEK_API_KEYæœªè®¾ç½®")

            # åˆ›å»ºä¸ä½¿ç”¨ä»£ç†çš„httpxå®¢æˆ·ç«¯ï¼ˆtrust_env=Falseç¦ç”¨æ‰€æœ‰ä»£ç†æ£€æµ‹ï¼‰
            http_client = httpx.Client(trust_env=False)

            client = openai.OpenAI(
                api_key=self.deepseek_api_key,
                base_url="https://api.deepseek.com",
                http_client=http_client
            )

            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = []
            if system_instruction:
                messages.append({"role": "system", "content": system_instruction})
            messages.append({"role": "user", "content": prompt})

            response = client.chat.completions.create(
                model=model_id,
                messages=messages
            )

            logger.info("DeepSeek APIè°ƒç”¨æˆåŠŸ")
            return response.choices[0].message.content

        except Exception as e:
            logger.error(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise RuntimeError(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {str(e)}")

    @retry_on_failure(max_retries=3, delay=1)
    def _call_gemini(self, prompt: str, model_id: str = "gemini-2.0-flash-exp") -> str:
        """è°ƒç”¨Gemini API"""
        logger.info(f"è°ƒç”¨Gemini APIï¼Œæ¨¡å‹: {model_id}")
        try:
            import google.generativeai as genai

            if not self.gemini_api_key:
                raise ValueError("GEMINI_API_KEYæœªè®¾ç½®")

            genai.configure(api_key=self.gemini_api_key)
            model = genai.GenerativeModel(model_id)

            response = model.generate_content(prompt)
            logger.info("Gemini APIè°ƒç”¨æˆåŠŸ")
            return response.text

        except Exception as e:
            logger.error(f"Gemini APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise RuntimeError(f"Gemini APIè°ƒç”¨å¤±è´¥: {str(e)}")

    @retry_on_failure(max_retries=3, delay=1)
    def _call_openai(self, prompt: str, model_id: str = "gpt-4") -> str:
        """è°ƒç”¨OpenAI APIï¼ˆGPT-4ç­‰ï¼‰"""
        logger.info(f"è°ƒç”¨OpenAI APIï¼Œæ¨¡å‹: {model_id}")
        try:
            import openai

            if not self.openai_api_key:
                raise ValueError("OPENAI_API_KEYæœªè®¾ç½®")

            client = openai.OpenAI(api_key=self.openai_api_key)

            response = client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )

            logger.info("OpenAI APIè°ƒç”¨æˆåŠŸ")
            return response.choices[0].message.content

        except Exception as e:
            logger.error(f"OpenAI APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise RuntimeError(f"OpenAI APIè°ƒç”¨å¤±è´¥: {str(e)}")

            logger.info("GPT-4 APIè°ƒç”¨æˆåŠŸ")
            return response.choices[0].message.content

        except Exception as e:
            logger.error(f"GPT-4 APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise RuntimeError(f"GPT-4 APIè°ƒç”¨å¤±è´¥: {str(e)}")

    def _parse_extraction_result(self, ai_response: str) -> Dict[str, List[Dict]]:
        """
        è§£æAIå“åº”ç»“æœ

        æå–JSONä»£ç å—å¹¶è§£æ
        """
        try:
            # å°è¯•æå–JSONä»£ç å—
            import re
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', ai_response, re.DOTALL)

            if json_match:
                json_str = json_match.group(1)
            else:
                # å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
                json_str = ai_response.strip()

            # è§£æJSON
            result = json.loads(json_str)

            # éªŒè¯ç»“æ„
            if not isinstance(result, dict):
                raise ValueError("è¿”å›ç»“æœä¸æ˜¯å­—å…¸æ ¼å¼")

            if 'characters' not in result:
                result['characters'] = []
            if 'props' not in result:
                result['props'] = []
            if 'scenes' not in result:
                result['scenes'] = []

            return result

        except json.JSONDecodeError as e:
            raise RuntimeError(f"AIå“åº”JSONè§£æå¤±è´¥: {str(e)}\nå“åº”å†…å®¹: {ai_response[:500]}")
        except Exception as e:
            raise RuntimeError(f"è§£æAIå“åº”å¤±è´¥: {str(e)}")


# å•ä¾‹å®ä¾‹
_ai_service_instance: Optional[AIService] = None


def get_ai_service(model: str = 'claude-sonnet-4-5') -> AIService:
    """
    è·å–AIæœåŠ¡å®ä¾‹

    Args:
        model: æ¨¡å‹æ ‡è¯†ç¬¦ï¼ˆå¦‚'claude-sonnet-4-5'ï¼‰æˆ–æ—§çš„æšä¸¾å€¼ï¼ˆå¦‚'claude'ï¼‰

    Returns:
        AIServiceå®ä¾‹
    """
    # å…¼å®¹æ—§çš„æšä¸¾å€¼
    if isinstance(model, AIModel):
        model = model.value

    return AIService(model)


def get_available_models() -> List[Dict[str, str]]:
    """
    è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹é…ç½®

    Returns:
        æ¨¡å‹é…ç½®åˆ—è¡¨ï¼Œæ¯ä¸ªæ¨¡å‹åŒ…å«ï¼šid, name, provider, description
    """
    models = []
    for model_id, config in MODEL_CONFIGS.items():
        models.append({
            'id': model_id,
            'name': config['name'],
            'provider': config['provider'],
            'description': config['description']
        })
    return models


# å…¨å±€æœåŠ¡å®ä¾‹ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼‰
_ai_service_instance = None


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    test_script = """
    ã€ç¬¬1åœºã€‘
    åœºæ™¯ï¼šå’–å•¡é¦† - ä¸‹åˆ

    å¼ ä¸‰ååœ¨çª—è¾¹ï¼Œæ‰‹é‡Œæ‹¿ç€ä¸€å°æ³›é»„çš„ä¿¡ä»¶ã€‚

    å¼ ä¸‰ï¼šï¼ˆä½å£°è‡ªè¯­ï¼‰ç»ˆäºæ‰¾åˆ°äº†...

    æå››æ¨é—¨è€Œå…¥ï¼Œå¾„ç›´èµ°å‘å¼ ä¸‰ã€‚

    æå››ï¼šæ‰¾åˆ°ä»€ä¹ˆäº†ï¼Ÿ
    å¼ ä¸‰ï¼šï¼ˆé€’è¿‡ä¿¡ä»¶ï¼‰ä½ è‡ªå·±çœ‹ã€‚
    """

    service = AIService(AIModel.CLAUDE)
    try:
        result = service.extract_assets(test_script, 1)
        print("æå–ç»“æœï¼š")
        print(json.dumps(result, ensure_ascii=False, indent=2))
    except Exception as e:
        print(f"é”™è¯¯: {e}")
